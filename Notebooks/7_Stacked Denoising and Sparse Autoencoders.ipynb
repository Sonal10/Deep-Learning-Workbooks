{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DLVC WS 2017\n",
    "\n",
    "Tutorial 7: Stacked Denoising and Sparse Autoencoders\n",
    "=="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Packages\n",
    "=="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from torch.autograd import Function\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data:\n",
    "==============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "BatchSize = 1000\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./MNIST', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BatchSize,\n",
    "                                          shuffle=True, num_workers=4) # Creating dataloader\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./MNIST', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=BatchSize,\n",
    "                                         shuffle=False, num_workers=4) # Creating dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check availability of GPU\n",
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    print('GPU is available!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the Sparse Autoencoder:\n",
    "==============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class L1Penalty(Function):\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, input, l1weight):\n",
    "        ctx.save_for_backward(input)\n",
    "        ctx.l1weight = l1weight\n",
    "        return input\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        input, = ctx.saved_variables\n",
    "        grad_input = input.clone().sign().mul(self.l1weight)\n",
    "        grad_input += grad_output\n",
    "        return grad_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(28*28, 400),\n",
    "            nn.Tanh())\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(400, 28*28),\n",
    "            nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = L1Penalty.apply(x, 0.1)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = autoencoder()\n",
    "print(net)\n",
    "\n",
    "if use_gpu:\n",
    "    net = net.double().cuda()\n",
    "else:\n",
    "    net = net.double()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Autoencoder:\n",
    "==========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 20\n",
    "learning_rate = 1e-3\n",
    "noise_mean = 0.1\n",
    "noise_std = 0.2\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr = learning_rate) # Adam optimizer for optimization\n",
    "for epoch in range(iterations):  # loop over the dataset multiple times\n",
    "\n",
    "    runningLoss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # wrap them in Variable\n",
    "        if use_gpu:\n",
    "            ideal_outputs = Variable(inputs.view(-1, 28*28).double()).cuda()\n",
    "            noise = Variable(ideal_outputs.data.new(ideal_outputs.size()).normal_(noise_mean, noise_std).double()).cuda()\n",
    "            inputs = Variable(torch.clamp((ideal_outputs + noise).data,0,1).double()).cuda()\n",
    "        else:\n",
    "            ideal_outputs = Variable(inputs.view(-1, 28*28).double())\n",
    "            noise = Variable(ideal_outputs.data.new(ideal_outputs.size()).normal_(noise_mean, noise_std).double())\n",
    "            inputs = Variable(torch.clamp((ideal_outputs + noise).data,0,1).double())\n",
    "\n",
    "        optimizer.zero_grad()  # zeroes the gradient buffers of all parameters\n",
    "        outputs = net(inputs) # forward \n",
    "        loss = criterion(outputs, ideal_outputs) # calculate loss\n",
    "        loss.backward() #  backpropagate the loss\n",
    "        optimizer.step()\n",
    "        runningLoss += loss.data[0]\n",
    "    print('At Iteration : %d / %d  ;  Mean-Squared Error : %f'%(epoch + 1,iterations,\n",
    "                                                                        runningLoss/(60000/BatchSize)))\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Stacked Denoising and Sparse Autoencoder:\n",
    "================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding New Layer (Stacking)\n",
    "net.encoder.add_module('New_Encoder_Layer', nn.Sequential(nn.Linear(400, 256),nn.Tanh()))\n",
    "net.encoder.add_module('New_Decoder_Layer', nn.Sequential(nn.Linear(256, 400),nn.Tanh()))\n",
    "print(net)\n",
    "if use_gpu:\n",
    "    net = net.double().cuda()\n",
    "else:\n",
    "    net = net.double()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Autoencoder:\n",
    "=========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(iterations):  # loop over the dataset multiple times\n",
    "\n",
    "    runningLoss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # wrap them in Variable\n",
    "        if use_gpu:\n",
    "            ideal_outputs = Variable(inputs.view(-1, 28*28).double()).cuda()\n",
    "            noise = Variable(ideal_outputs.data.new(ideal_outputs.size()).normal_(noise_mean, noise_std).double()).cuda()\n",
    "            inputs = Variable(torch.clamp((ideal_outputs + noise).data,0,1).double()).cuda()\n",
    "        else:\n",
    "            ideal_outputs = Variable(inputs.view(-1, 28*28).double())\n",
    "            noise = Variable(ideal_outputs.data.new(ideal_outputs.size()).normal_(noise_mean, noise_std).double())\n",
    "            inputs = Variable(torch.clamp((ideal_outputs + noise).data,0,1).double())\n",
    "\n",
    "        optimizer.zero_grad()  # zeroes the gradient buffers of all parameters\n",
    "        outputs = net(inputs) # forward \n",
    "        loss = criterion(outputs, ideal_outputs) # calculate loss\n",
    "        loss.backward() #  backpropagate the loss\n",
    "        optimizer.step()\n",
    "        runningLoss += loss.data[0]\n",
    "    print('At Iteration : %d / %d  ;  Mean-Squared Error : %f'%(epoch + 1,iterations,\n",
    "                                                                        runningLoss/(60000/BatchSize)))\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Autoencoder Performance:\n",
    "================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to show an image\n",
    "def imshow(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "if use_gpu:\n",
    "    ideal_outputs = Variable(images[0].view(-1,28*28).double()).cuda()\n",
    "    noise = Variable(ideal_outputs.data.new(ideal_outputs.size()).normal_(noise_mean, noise_std).double()).cuda()\n",
    "    inputs = ideal_outputs + noise\n",
    "    outImg = net(inputs).data\n",
    "    outImg = outImg.view(-1,28,28).cpu()\n",
    "else:\n",
    "    ideal_outputs = Variable(images[0].view(-1,28*28).double())\n",
    "    noise = Variable(ideal_outputs.data.new(ideal_outputs.size()).normal_(noise_mean, noise_std).double())\n",
    "    inputs = ideal_outputs + noise\n",
    "    outImg = net(inputs).data\n",
    "    outImg = outImg.view(-1,28,28)\n",
    "\n",
    "dispImg = torch.Tensor(2,1,28,28)\n",
    "dispImg[0] = torch.clamp(inputs.data.view(-1,28,28).cpu(),0,1)\n",
    "dispImg[1] = outImg\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(dispImg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
