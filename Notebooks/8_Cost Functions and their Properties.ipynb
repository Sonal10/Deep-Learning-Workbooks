{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DLVC WS 2017\n",
    "\n",
    "Tutorial 8: Cost Functions and their Properties\n",
    "=="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Packages\n",
    "=="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import pytorch_ssim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data:\n",
    "==============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "BatchSize = 100\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./MNIST', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BatchSize,\n",
    "                                          shuffle=True, num_workers=4) # Creating dataloader\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./MNIST', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=BatchSize,\n",
    "                                         shuffle=False, num_workers=4) # Creating dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check availability of GPU\n",
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    print('GPU is available!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the Autoencoder:\n",
    "==============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(28*28, 400),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(400, 256),\n",
    "            nn.ReLU())\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(256, 400),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(400, 28*28),\n",
    "            nn.ReLU())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net1 = autoencoder()\n",
    "net2 = autoencoder()\n",
    "\n",
    "if use_gpu:\n",
    "    net1 = net1.double().cuda()\n",
    "    net2 = net2.double().cuda()\n",
    "else:\n",
    "    net1 = net1.double()\n",
    "    net2 = net2.double()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Autoencoder:\n",
    "==========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Train(model,optimizer,criterion,IP,LB):\n",
    "    optimizer.zero_grad()\n",
    "    OP = model(IP)\n",
    "    loss = criterion(OP, LB)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "iterations = 10\n",
    "\n",
    "optimizer1 = optim.Adam(net1.parameters(), lr=1e-4)\n",
    "optimizer2 = optim.Adam(net2.parameters(), lr=1e-4)\n",
    "\n",
    "criterion1 = nn.MSELoss()\n",
    "criterion2 = nn.L1Loss()\n",
    "\n",
    "Plotssim1 = []\n",
    "Plotssim2 = []\n",
    "\n",
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "if use_gpu:\n",
    "    testinputs = Variable(images[0].view(-1, 28*28).double()).cuda()\n",
    "else:\n",
    "    testinputs = Variable(images[0].view(-1, 28*28).double()) \n",
    "\n",
    "for epoch in range(iterations):  # loop over the dataset multiple times\n",
    "    ssim1 = 0.0\n",
    "    ssim2 = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "        inputs, labels = data\n",
    "        if use_gpu:\n",
    "            inputs = Variable(inputs.view(-1, 28*28).double()).cuda()\n",
    "        else:\n",
    "            inputs = Variable(inputs.view(-1, 28*28).double())\n",
    "        Train(net1,optimizer1,criterion1,inputs,inputs)\n",
    "        Train(net2,optimizer2,criterion2,inputs,inputs)        \n",
    "    outputs = net1(testinputs)\n",
    "    ssim1 = pytorch_ssim.ssim(Variable(testinputs.data.view(1,1,28,28).double()), Variable(outputs.data.view(1,1,28,28).double()))\n",
    "    outputs = net2(testinputs)\n",
    "    ssim2 = pytorch_ssim.ssim(Variable(testinputs.data.view(1,1,28,28).double()), Variable(outputs.data.view(1,1,28,28).double()))\n",
    "    Plotssim1.append(float(ssim1))\n",
    "    Plotssim2.append(float(ssim2))\n",
    "    print('At Epoch %d ; SSIM Index (MSE):  %f ; SSIM Index (L1):  %f '%((epoch+1),ssim1,ssim2))\n",
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "fig_size[0] = 10\n",
    "fig_size[1] = 10\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "fig = plt.figure()         \n",
    "plt.plot(range(epoch+1),Plotssim1,'r-',label='SSIM Index (MSE)')\n",
    "plt.plot(range(epoch+1),Plotssim2,'g-',label='SSIM Index (L1)')      \n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Testing SSIM')  \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Network: \n",
    "================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.Layer1 = nn.Sequential(\n",
    "            nn.Linear(28*28, 400),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(400, 256),\n",
    "            nn.ReLU())\n",
    "        self.Layer2 = nn.Sequential(\n",
    "            nn.Linear(256, 10))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.Layer1(x)\n",
    "        x = self.Layer2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net1 = NeuralNet()\n",
    "net2 = NeuralNet()\n",
    "net3 = NeuralNet()\n",
    "\n",
    "if use_gpu:\n",
    "    net1 = net1.double().cuda()\n",
    "    net2 = net2.double().cuda()\n",
    "    net3 = net3.double().cuda()\n",
    "else:\n",
    "    net1 = net1.double()\n",
    "    net2 = net2.double()\n",
    "    net3 = net3.double()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Classifier:\n",
    "==========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def TrainClassifier(model,optimizer,criterion,IP,LB,lossType):\n",
    "    optimizer.zero_grad()\n",
    "    OP = model(IP)\n",
    "    \n",
    "    if lossType=='CEL':\n",
    "        loss = criterion(OP, LB)        \n",
    "    else:\n",
    "        loss = criterion(F.log_softmax(OP), LB)        \n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 10\n",
    "learning_rate = 0.9\n",
    "criterion1 = nn.CrossEntropyLoss()\n",
    "criterion2 = nn.NLLLoss()\n",
    "criterion3 = nn.MultiMarginLoss()\n",
    "\n",
    "optimizer1 = optim.SGD(net1.parameters(), lr=1e-3)\n",
    "optimizer2 = optim.SGD(net2.parameters(), lr=1e-3)\n",
    "optimizer3 = optim.SGD(net3.parameters(), lr=1e-3)\n",
    "\n",
    "Plotacc1 = []\n",
    "Plotacc2 = []\n",
    "Plotacc3 = []\n",
    "\n",
    "for epoch in range(iterations):  # loop over the dataset multiple times\n",
    "\n",
    "    correct1 = 0\n",
    "    correct2 = 0\n",
    "    correct3 = 0\n",
    "    total = 0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        if use_gpu:\n",
    "            inputs, labels = Variable(inputs.view(-1, 28*28).double()).cuda(), Variable(labels).cuda()\n",
    "        else:\n",
    "            inputs, labels = Variable(inputs.view(-1, 28*28).double()), Variable(labels)\n",
    "            \n",
    "        TrainClassifier(net1,optimizer1,criterion1,inputs,labels,'CEL')\n",
    "        TrainClassifier(net2,optimizer2,criterion2,inputs,labels,'NLL')\n",
    "        TrainClassifier(net3,optimizer3,criterion3,inputs,labels,'MML')\n",
    "        \n",
    "    for data in testloader:\n",
    "        inputs, labels = data\n",
    "        if use_gpu:\n",
    "            inputs, labels = Variable(inputs.view(-1, 28*28).double()).cuda(), labels.cuda()\n",
    "        else:\n",
    "            inputs, labels = Variable(inputs.view(-1, 28*28).double()), labels\n",
    "        total += labels.size(0)\n",
    "        \n",
    "        outputs = net1(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct1 += (predicted == labels).sum()\n",
    "        \n",
    "        outputs = net2(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct2 += (predicted == labels).sum()\n",
    "        \n",
    "        outputs = net3(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct3 += (predicted == labels).sum()\n",
    "\n",
    "    Plotacc1.append(correct1/float(total))\n",
    "    Plotacc2.append(correct2/float(total))\n",
    "    Plotacc3.append(correct3/float(total))\n",
    "    print('At Epoch %d ;Acc (CrossEntropy):  %f ;Acc (NegativeLogLikelihood):  %f ;Acc (MultiMarginLoss):  %f'%((epoch+1),correct1/float(total),correct2/float(total),correct3/float(total)))\n",
    "fig = plt.figure()        \n",
    "plt.plot(range(epoch+1),Plotacc1,'r-',label='Cross Entropy Loss')\n",
    "plt.plot(range(epoch+1),Plotacc2,'g-',label='Negative Log Likelihood Loss')   \n",
    "plt.plot(range(epoch+1),Plotacc3,'b-',label='Multi Margin Loss')  \n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Testing Accuracy')  \n",
    "print('Finished Training')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
