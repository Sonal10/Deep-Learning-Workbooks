{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DLVC WS 2017\n",
    "\n",
    "Tutorial 6: CIFAR Classification (Autoencoders)\n",
    "=="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Packages\n",
    "=="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data:\n",
    "==============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "BatchSize = 100\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./CIFAR10', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BatchSize,\n",
    "                                          shuffle=True, num_workers=4) # Creating dataloader\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./CIFAR10', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=BatchSize,\n",
    "                                         shuffle=False, num_workers=4) # Creating dataloader\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check availability of GPU\n",
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    print('GPU is available!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the Autoencoder:\n",
    "==============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(3*32*32, 900),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(900, 256),\n",
    "            nn.ReLU())\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(256, 900),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(900, 3*32*32),\n",
    "            nn.ReLU())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = autoencoder()\n",
    "print(net)\n",
    "\n",
    "if use_gpu:\n",
    "    net = net.double().cuda()\n",
    "else:\n",
    "    net = net.double()\n",
    "        \n",
    "init_weights = copy.deepcopy(net.encoder[0].weight.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Autoencoder:\n",
    "==========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# functions to show an image\n",
    "def imshow(img, strlabel):\n",
    "    npimg = img.numpy()\n",
    "    npimg = np.abs(npimg)\n",
    "    fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "    fig_size[0] = 10\n",
    "    fig_size[1] = 10\n",
    "    plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "    plt.figure()\n",
    "    plt.title(strlabel)\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 100\n",
    "learning_rate = 0.9\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "printImg = torch.Tensor(iterations/10,2,3,32,32)\n",
    "\n",
    "for epoch in range(iterations):  # loop over the dataset multiple times\n",
    "    runningLoss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        # wrap them in Variable\n",
    "        if use_gpu:\n",
    "            inputs = Variable(inputs.view(-1, 3*32*32).double()).cuda()\n",
    "        else:\n",
    "            inputs = Variable(inputs.view(-1, 3*32*32).double())\n",
    "\n",
    "        net.zero_grad()  # zeroes the gradient buffers of all parameters\n",
    "        outputs = net(inputs) # forward \n",
    "        loss = criterion(outputs, inputs) # calculate loss\n",
    "        loss.backward() #  backpropagate the loss\n",
    "        for f in net.parameters():\n",
    "            f.data.sub_(f.grad.data * learning_rate) # weight = weight - learning_rate * gradient (Update Weights)\n",
    "        runningLoss += loss.data[0]\n",
    "        \n",
    "    print('At Iteration : %d / %d  ;  Mean-Squared Error : %f'%(epoch + 1,iterations,\n",
    "                                                                        runningLoss/(60000/BatchSize)))\n",
    "    if epoch%10 == 0:\n",
    "        if use_gpu:\n",
    "            outImg = net(Variable((images[0].view(-1,3*32*32).double().cuda()))).data\n",
    "            outImg = outImg.view(3,32,32).cpu()\n",
    "        else:\n",
    "            outImg = net(Variable((images[0].view(-1,3*32*32).double()))).data\n",
    "            outImg = outImg.view(3,32,32).cpu()\n",
    "\n",
    "        dispImg = torch.Tensor(2,3,32,32)\n",
    "        dispImg[0] = images[0]\n",
    "        dispImg[1] = outImg\n",
    "        printImg[epoch/10] = dispImg\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(iterations/10):\n",
    "    imshow(torchvision.utils.make_grid(printImg[i]), 'Autoencoder Performance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoder Weights Visualization:\n",
    "======================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trained_weights = copy.deepcopy(net.encoder[0].weight.data)\n",
    "d_weights = init_weights - trained_weights \n",
    "\n",
    "if use_gpu:\n",
    "    init_weights = init_weights.view(900,3,32,32).cpu()\n",
    "    trained_weights = trained_weights.view(900,3,32,32).cpu()\n",
    "    d_weights = d_weights.view(900,3,32,32).cpu()\n",
    "else:\n",
    "    init_weights = init_weights.view(900,3,32,32)\n",
    "    trained_weights = trained_weights.view(900,3,32,32)\n",
    "    d_weights = d_weights.view(900,3,32,32)\n",
    "\n",
    "imshow(torchvision.utils.make_grid(init_weights,nrow=30,normalize=True),'Initial Weights')\n",
    "imshow(torchvision.utils.make_grid(trained_weights,nrow=30,normalize=True),'Trained Weights')\n",
    "imshow(torchvision.utils.make_grid(d_weights,nrow=30,normalize=True), 'Weight update')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modifying the autoencoder for classification: \n",
    "================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the decoder module from the autoencoder\n",
    "new_classifier = nn.Sequential(*list(net.children())[:-1])\n",
    "net = new_classifier\n",
    "# Adding linear layer for 10-class classification problem\n",
    "net.add_module('classifier', nn.Sequential(nn.Linear(256, 10),nn.LogSoftmax()))\n",
    "print(net)\n",
    "if use_gpu:\n",
    "    net = net.double().cuda()\n",
    "else:\n",
    "    net = net.double()\n",
    "# Copying initial weights  for visualization\n",
    "cll_weights = copy.deepcopy(net[0][0].weight.data)\n",
    "init_classifier_weights = copy.deepcopy(net.classifier[0].weight.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Classifier:\n",
    "==========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 10\n",
    "learning_rate = 0.1\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(iterations):  # loop over the dataset multiple times\n",
    "\n",
    "    runningLoss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # wrap them in Variable\n",
    "        if use_gpu:\n",
    "            inputs, labels = Variable(inputs.view(-1, 3*32*32).double()).cuda(), Variable(labels).cuda()\n",
    "        else:\n",
    "            inputs, labels = Variable(inputs.view(-1, 3*32*32).double()), Variable(labels)\n",
    "\n",
    "        net.zero_grad()  # zeroes the gradient buffers of all parameters\n",
    "        outputs = net(inputs) # forward \n",
    "        loss = criterion(outputs, labels) # calculate loss\n",
    "        loss.backward() #  backpropagate the loss\n",
    "        for f in net.parameters():\n",
    "            f.data.sub_(f.grad.data * learning_rate) # weight = weight - learning_rate * gradient (Update Weights)\n",
    "        runningLoss += loss.data[0]\n",
    "        correct = 0\n",
    "        total = 0\n",
    "    for data in testloader:\n",
    "        inputs, labels = data\n",
    "        if use_gpu:\n",
    "            inputs, labels = Variable(inputs.view(-1, 3*32*32).double()).cuda(), labels.cuda()\n",
    "        else:\n",
    "            inputs, labels = Variable(inputs.view(-1, 3*32*32).double()), labels\n",
    "        outputs = net(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum()\n",
    "    print('At Iteration : %d / %d  ;  Train Error : %f ;Test Accuracy : %f'%(epoch + 1,iterations,\n",
    "                                                                        runningLoss/(60000/BatchSize),100 * correct /float(total)))\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoder Weights Visualization:\n",
    "======================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cll_weights_ft = copy.deepcopy(net[0][0].weight.data)\n",
    "d_weights = cll_weights-cll_weights_ft \n",
    "\n",
    "if use_gpu:\n",
    "    cll_weights = cll_weights.view(900,3,32,32).cpu()\n",
    "    cll_weights_ft = cll_weights_ft.view(900,3,32,32).cpu()\n",
    "    d_weights = d_weights.view(900,3,32,32).cpu()\n",
    "else:\n",
    "    cll_weights = cll_weights.view(900,3,32,32)\n",
    "    cll_weights_ft = cll_weights_ft.view(900,3,32,32)\n",
    "    d_weights = d_weights.view(900,3,32,32)\n",
    "\n",
    "imshow(torchvision.utils.make_grid(cll_weights,nrow=30,normalize=True),'Trained Weights')\n",
    "imshow(torchvision.utils.make_grid(cll_weights_ft,nrow=30,normalize=True),'Finetuned Weights')\n",
    "imshow(torchvision.utils.make_grid(d_weights,nrow=30,normalize=True), 'Weight update')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Performance of different Classes:\n",
    "=================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    if use_gpu:\n",
    "        outputs = net(Variable(images.view(-1, 3*32*32).double().cuda()))\n",
    "        _, predicted = torch.max(outputs.data.cpu(), 1)\n",
    "    else:\n",
    "        outputs = net(Variable(images.view(-1, 3*32*32).double()))\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "    c = (predicted == labels).squeeze()\n",
    "    for i in range(BatchSize):\n",
    "        label = labels[i]\n",
    "        class_correct[label] += c[i]\n",
    "        class_total[label] += 1\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %f %%' % (\n",
    "        classes[i], 100 * class_correct[i] / float(class_total[i])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
