{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DLVC 2017\n",
    "# Tutorial 2: MNIST Digits Classification (Classical Approach)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST database (http://yann.lecun.com/exdb/mnist/)\n",
    "\n",
    "Consists of four files: <br>\n",
    "* train-images-idx3-ubyte.gz:  training set images (9912422 bytes) <br>\n",
    "* train-labels-idx1-ubyte.gz:  training set labels (28881 bytes) <br>\n",
    "* t10k-images-idx3-ubyte.gz:   test set images (1648877 bytes) <br>\n",
    "* t10k-labels-idx1-ubyte.gz:   test set labels (4542 bytes)  <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from torchvision import datasets\n",
    "from pylab import *\n",
    "import pickle\n",
    "from skimage import feature\n",
    "import struct\n",
    "from sklearn import preprocessing\n",
    "import os\n",
    "\n",
    "if not os.path.exists('tut02-results'):\n",
    "    os.makedirs('tut02-results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loading dataset\n",
    "trainSet = datasets.MNIST('./MNIST/', train=True, download=True)\n",
    "testSet = datasets.MNIST('./MNIST/', train=False, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('No. of training samples: '+str(len(trainSet)))\n",
    "print('No. of testing samples: '+str(len(testSet)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Feature extraction and data preparation\n",
    "# Training features\n",
    "train_greycoHomFeat = []\n",
    "train_greycoConFeat = []\n",
    "train_greycoEnFeat = []\n",
    "train_greycoCorrFeat = []\n",
    "train_hogFeat = []\n",
    "train_lbpFeat = []\n",
    "train_label = np.zeros(len(trainSet))\n",
    "for num in range(len(trainSet)): \n",
    "    if (num+1)%10000==0:\n",
    "        print(str(num+1)+'/'+str(len(trainSet)))\n",
    "    img = trainSet[num][0]\n",
    "    train_label[num] = trainSet[num][1]\n",
    "    train_greycoHomFeat.append(feature.greycoprops(feature.greycomatrix(array(img), [1], [np.pi/4],normed=True),prop='homogeneity'))\n",
    "    train_greycoConFeat.append(feature.greycoprops(feature.greycomatrix(array(img), [1], [np.pi/4],normed=True),prop='contrast') )\n",
    "    train_greycoEnFeat.append(feature.greycoprops(feature.greycomatrix(array(img), [1], [np.pi/4],normed=True),prop='energy'))\n",
    "    train_greycoCorrFeat.append(feature.greycoprops(feature.greycomatrix(array(img), [1], [np.pi/4],normed=True),prop='correlation'))\n",
    "    train_hogFeat.append(feature.hog(array(img), orientations=4, pixels_per_cell=(5,5))) \n",
    "    train_lbpFeat.append(feature.local_binary_pattern(array(img), 5, 3)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Testing features\n",
    "test_greycoHomFeat = []\n",
    "test_greycoConFeat = []\n",
    "test_greycoEnFeat = []\n",
    "test_greycoCorrFeat = []\n",
    "test_hogFeat = []\n",
    "test_lbpFeat = []\n",
    "test_label = np.zeros(len(testSet))\n",
    "for num in range(len(testSet)):  \n",
    "    if (num+1)%5000==0:\n",
    "        print(str(num+1)+'/'+str(len(testSet)))\n",
    "    img = testSet[num][0]\n",
    "    test_label[num] = testSet[num][1]\n",
    "    test_greycoHomFeat.append(feature.greycoprops(feature.greycomatrix(array(img), [1], [np.pi/4],normed=True),prop='homogeneity'))\n",
    "    test_greycoConFeat.append(feature.greycoprops(feature.greycomatrix(array(img), [1], [np.pi/4],normed=True),prop='contrast') )\n",
    "    test_greycoEnFeat.append(feature.greycoprops(feature.greycomatrix(array(img), [1], [np.pi/4],normed=True),prop='energy'))\n",
    "    test_greycoCorrFeat.append(feature.greycoprops(feature.greycomatrix(array(img), [1], [np.pi/4],normed=True),prop='correlation'))\n",
    "    test_hogFeat.append(feature.hog(array(img), orientations=4, pixels_per_cell=(5,5))) \n",
    "    test_lbpFeat.append(feature.local_binary_pattern(array(img), 5, 3)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data\n",
    "trainFeat = np.zeros((60000,1112))\n",
    "for num in range(60000):    \n",
    "    trainFeat[num][:] = np.concatenate((train_greycoHomFeat[num].reshape(1,),train_greycoConFeat[num].reshape(1,),\n",
    "                            train_greycoEnFeat[num].reshape(1,),train_greycoCorrFeat[num].reshape(1,),\n",
    "                                        train_hogFeat[num],train_lbpFeat[num].reshape(28*28)),axis=0)\n",
    "\n",
    "testFeat = np.zeros((10000,1112))\n",
    "for num in range(10000):    \n",
    "    trainFeat[num][:] = np.concatenate((test_greycoHomFeat[num].reshape(1,),test_greycoConFeat[num].reshape(1,),\n",
    "                            test_greycoEnFeat[num].reshape(1,),test_greycoCorrFeat[num].reshape(1,),\n",
    "                                        test_hogFeat[num],test_lbpFeat[num].reshape(28*28)),axis=0)\n",
    "trainFeat_scaled = preprocessing.scale(trainFeat)\n",
    "testFeat_scaled = preprocessing.scale(testFeat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with open('tut02-results/trainFeat_scaled.pkl','wb') as f:\n",
    "#     pickle.dump(trainFeat_scaled,f)\n",
    "# with open('tut02-results/testFeat_scaled.pkl','wb') as f:\n",
    "#     pickle.dump(testFeat_scaled,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scikitlearn [documentation](goo.gl/F1Q1Fa) for MLP classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "nn = MLPClassifier(hidden_layer_sizes=(100,), max_iter=10, alpha=1e-4,\n",
    "                    solver='sgd', verbose=True, tol=1e-4, random_state=1,\n",
    "                    learning_rate_init=1e-2)\n",
    "nn.fit(trainFeat_scaled, train_label)       \n",
    "prediction = nn.predict(testFeat_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Training set score: %f\" % nn.score(trainFeat_scaled, train_label)) # mean accuracy\n",
    "print(\"Test set score: %f\" % nn.score(testFeat_scaled, test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
